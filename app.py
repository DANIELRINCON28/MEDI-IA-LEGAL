"""
Interfaz de Usuario con Streamlit para MEDI-IA-LEGAL
"""

import streamlit as st
from graph import mediation_graph

# ============================================================================
# CONFIGURACIÃ“N DE LA PÃGINA
# ============================================================================

st.set_page_config(
    page_title="MEDI-IA-LEGAL",
    page_icon="âš–ï¸",
    layout="wide"
)

# ============================================================================
# TÃTULO Y DESCRIPCIÃ“N
# ============================================================================

st.title("âš–ï¸ MEDI-IA-LEGAL: MediaciÃ³n de Divorcio Asistida por IA")
st.caption("Prototipo basado en LangGraph y la Ley 2442 de 2024")

st.markdown("""
---
**Sistema de MediaciÃ³n Inteligente** para propuestas de divorcio unilateral en Colombia.  
Este asistente te guiarÃ¡ a travÃ©s de los 3 puntos nodales:
1. ğŸ’° LiquidaciÃ³n de la Sociedad Conyugal
2. ğŸ’µ Obligaciones Alimentarias  
3. ğŸ‘¨â€ğŸ‘©â€ğŸ‘§â€ğŸ‘¦ Acuerdos sobre Hijos Menores

*El sistema vela por la equidad y el cumplimiento de la ley colombiana.*
---
""")

# ============================================================================
# INICIALIZACIÃ“N DEL ESTADO DE LA SESIÃ“N
# ============================================================================

# ConfiguraciÃ³n del thread para LangGraph
if "config" not in st.session_state:
    st.session_state.config = {
        "configurable": {
            "thread_id": "demo_thread"
        }
    }

# Inicializar el historial de chat
if "messages" not in st.session_state:
    st.session_state.messages = []
    
    # Mensaje de bienvenida automÃ¡tico
    with st.spinner("ğŸ¤– MEDI-IA-LEGAL se estÃ¡ iniciando..."):
        try:
            # Invocar el grafo con un mensaje de inicio
            initial_message = "Hola, estoy listo para comenzar la mediaciÃ³n."
            response = mediation_graph.invoke(
                {"messages": [("user", initial_message)]},
                config=st.session_state.config
            )
            
            # Extraer la respuesta de la IA
            if response and "messages" in response and len(response["messages"]) > 0:
                ai_message = response["messages"][-1]
                if hasattr(ai_message, "content"):
                    st.session_state.messages.append({
                        "role": "assistant",
                        "content": ai_message.content
                    })
        except Exception as e:
            st.error(f"Error al inicializar: {str(e)}")
            st.info("ğŸ’¡ AsegÃºrate de haber configurado tu GROQ_API_KEY en el archivo .env")

# ============================================================================
# MOSTRAR HISTORIAL DE CHAT
# ============================================================================

for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])

# ============================================================================
# ENTRADA DEL USUARIO
# ============================================================================

if prompt := st.chat_input("Escribe tu propuesta o respuesta..."):
    # AÃ±adir mensaje del usuario al historial
    st.session_state.messages.append({
        "role": "user",
        "content": prompt
    })
    
    # Mostrar mensaje del usuario
    with st.chat_message("user"):
        st.markdown(prompt)
    
    # Generar respuesta del asistente
    with st.chat_message("assistant"):
        with st.spinner("ğŸ¤– MEDI-IA-LEGAL estÃ¡ analizando..."):
            try:
                # Invocar el grafo
                response = mediation_graph.invoke(
                    {"messages": [("user", prompt)]},
                    config=st.session_state.config
                )
                
                # Extraer la respuesta de la IA
                if response and "messages" in response:
                    ai_message = response["messages"][-1]
                    
                    # Verificar si es un mensaje de contenido o una llamada a herramientas
                    if hasattr(ai_message, "content") and ai_message.content:
                        ai_response = ai_message.content
                    else:
                        # Si hay tool_calls, esperar a que se ejecuten
                        # El grafo deberÃ­a manejar esto automÃ¡ticamente
                        ai_response = "Procesando informaciÃ³n..."
                    
                    # Mostrar la respuesta
                    st.markdown(ai_response)
                    
                    # AÃ±adir al historial
                    st.session_state.messages.append({
                        "role": "assistant",
                        "content": ai_response
                    })
                else:
                    st.error("No se recibiÃ³ respuesta del sistema.")
                    
            except Exception as e:
                error_msg = f"Error: {str(e)}"
                st.error(error_msg)
                st.session_state.messages.append({
                    "role": "assistant",
                    "content": error_msg
                })

# ============================================================================
# SIDEBAR CON INFORMACIÃ“N
# ============================================================================

with st.sidebar:
    st.header("ğŸ“‹ InformaciÃ³n del Sistema")
    
    st.markdown("""
    ### ğŸ¯ Objetivo
    Facilitar la co-creaciÃ³n de una propuesta de divorcio justa y legal.
    
    ### ğŸ› ï¸ Herramientas Disponibles
    - **Legal Analyst**: Consulta el corpus jurÃ­dico
    - **Financial Calculator**: CÃ¡lculos de divisiÃ³n de bienes
    
    ### âš–ï¸ Barrera Ã‰tica
    El sistema rechazarÃ¡ propuestas injustas o ilegales.
    
    ### ğŸ“š Base Legal
    - Ley 2442 de 2024
    - CÃ³digo Civil Colombiano
    - InterÃ©s Superior del Menor
    """)
    
    st.divider()
    
    if st.button("ğŸ”„ Reiniciar ConversaciÃ³n"):
        st.session_state.messages = []
        st.session_state.config = {
            "configurable": {
                "thread_id": f"demo_thread_{len(st.session_state.messages)}"
            }
        }
        st.rerun()
    
    st.divider()
    st.caption("Desarrollado con LangGraph + Streamlit")
